---
title: "Stan User Guide Models"
author: "Chris Waller"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#####     Load Packages     #####

library(rstan)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)

options(mc.cores=parallel::detectCores())

#####     Create Data     #####

n_samples = 1e4

```

# Regression Models

## Linear Regression

```{r}

x_1_1 = cbind(runif(n_samples), runif(n_samples))
alpha_1_1 = 0.3
beta_1_1 = c(1.2, 1.6)
sigma_1_1 = 0.2
y_1_1 = alpha_1_1 + c(x_1_1 %*% beta_1_1) + rnorm(n_samples, 0, sigma_1_1)

linear_reg_data =
  list(
    N = n_samples,
    K = length(beta_1_1),
    y = y_1_1,
    x = x_1_1
  )

```

```{stan, output.var = "linear_reg_model"}

data {
  int<lower=0> N;   // number of data items
  int<lower=0> K;   // number of predictors
  matrix[N, K] x;   // predictor matrix
  vector[N] y;      // outcome vector
}
parameters {
  real alpha;           // intercept
  vector[K] beta;       // coefficients for predictors
  real<lower=0> sigma;  // error scale
}
model {
  y ~ normal(alpha + x * beta, sigma);  // likelihood
}

```

```{r}

linear_reg_then = Sys.time()

linear_reg =
  sampling(
    linear_reg_model,
    data = linear_reg_data,
    iter = 1000,
    chains = 3,
    refresh = 50,
    warmup = 250
  )

linear_reg_time = difftime(Sys.time(), linear_reg_then)

linear_reg_time

linear_reg_out = rstan::extract(linear_reg)

linear_reg_avg = lapply(linear_reg_out, function(x) colMeans(as.matrix(x)))

linear_reg_ggdata =
  data.frame(
    beta1 = linear_reg_out$beta[,1],
    beta2 = linear_reg_out$beta[,2],
    alpha = linear_reg_out$alpha,
    sigma = linear_reg_out$sigma
  ) %>%
  pivot_longer(
    cols = everything(),
    names_to = "param",
    values_to = "value"
  )

linear_reg_act =
  data.frame(
    param = c("beta1", "beta2", "alpha", "sigma"),
    value = c(beta_1_1, alpha_1_1, sigma_1_1)
  )

ggplot() + 
  geom_boxplot(
    data = linear_reg_ggdata,
    aes(
      x = factor(param),
      y = value,
      color = param
      )
    ) + 
  geom_point(
    data = linear_reg_act,
    aes(
      x = factor(param),
      y = value
    )
  ) + 
  theme(
    legend.position = "none"
  ) + 
  labs(
    title = "1.1 Linear Regression",
    y = "Value",
    x = "Parameter"
  ) +
  facet_wrap(
    ~ param,
    scales = "free"
  )

```

## The QR Reparameterization

```{r}

x_1_2 = cbind(runif(n_samples), runif(n_samples))
alpha_1_2 = 0.3
beta_1_2 = c(1.2, 1.6)
sigma_1_2 = 0.2
y_1_2 = alpha_1_2 + c(x_1_2 %*% beta_1_2) + rnorm(n_samples, 0, sigma_1_2)

qr_reparam_data =
  list(
    N = n_samples,
    K = length(beta_1_2),
    y = y_1_2,
    x = x_1_2
  )

```

```{stan, output.var = "qr_reparam_model"}

data {
  int<lower=0> N;   // number of data items
  int<lower=0> K;   // number of predictors
  matrix[N, K] x;   // predictor matrix
  vector[N] y;      // outcome vector
}
transformed data {
  matrix[N, K] Q_ast;
  matrix[K, K] R_ast;
  matrix[K, K] R_ast_inverse;
  // thin and scale the QR decomposition
  Q_ast = qr_Q(x)[, 1:K] * sqrt(N - 1);
  R_ast = qr_R(x)[1:K, ] / sqrt(N - 1);
  R_ast_inverse = inverse(R_ast);
}
parameters {
  real alpha;           // intercept
  vector[K] theta;      // coefficients on Q_ast
  real<lower=0> sigma;  // error scale
}
model {
  y ~ normal(Q_ast * theta + alpha, sigma);  // likelihood
}
generated quantities {
  vector[K] beta;
  beta = R_ast_inverse * theta; // coefficients on x
}

```

```{r}

qr_reparam_then = Sys.time()

qr_reparam =
  sampling(
    qr_reparam_model,
    data = qr_reparam_data,
    iter = 1000,
    chains = 3,
    refresh = 50,
    warmup = 250
  )

qr_reparam_time = difftime(Sys.time(), qr_reparam_then)

qr_reparam_time

qr_reparam_out = rstan::extract(qr_reparam)

qr_reparam_avg = lapply(qr_reparam_out, function(x) colMeans(as.matrix(x)))

qr_reparam_ggdata =
  data.frame(
    beta1 = qr_reparam_out$beta[,1],
    beta2 = qr_reparam_out$beta[,2],
    alpha = qr_reparam_out$alpha,
    sigma = qr_reparam_out$sigma
  ) %>%
  pivot_longer(
    cols = everything(),
    names_to = "param",
    values_to = "value"
  )

qr_reparam_act =
  data.frame(
    param = c("beta1", "beta2", "alpha", "sigma"),
    value = c(beta_1_2, alpha_1_2, sigma_1_2)
  )

ggplot() + 
  geom_boxplot(
    data = qr_reparam_ggdata,
    aes(
      x = factor(param),
      y = value,
      color = param
    )
  ) + 
  geom_point(
    data = qr_reparam_act,
    aes(
      x = factor(param),
      y = value
    )
  ) + 
  theme(
    legend.position = "none"
  ) + 
  labs(
    title = "1.2 QR Reparameterization",
    y = "Value",
    x = "Parameter"
  ) +
  facet_wrap(
    ~ param,
    scales = "free"
  )

```

## Priors for Coefficients and Scales

No model in this section.

## Robust Noise Models

```{r}

x_1_4 = cbind(runif(n_samples), runif(n_samples))
alpha_1_4 = 2
beta_1_4 = c(7, 9)
sigma_1_4 = 1.5
nu_degf = 5 # Degrees of freedom of t-distribution
y_1_4 = alpha_1_4 + c(x_1_4 %*% beta_1_4) + rt(n_samples, nu_degf) * sigma_1_4

robust_noise_data =
  list(
    N  = n_samples,
    K  = length(beta_1_4),
    y  = y_1_4,
    x  = x_1_4,
    nu = nu_degf
  )

```

```{stan, output.var = "robust_noise_model"}

data {
  int<lower=0> N;   // number of data items
  int<lower=0> K;   // number of predictors
  matrix[N, K] x;   // predictor matrix
  vector[N] y;      // outcome vector
  real<lower=0> nu; // Noise Degrees of freedom
}
transformed data {
  matrix[N, K] Q_ast;
  matrix[K, K] R_ast;
  matrix[K, K] R_ast_inverse;
  // thin and scale the QR decomposition
  Q_ast = qr_Q(x)[, 1:K] * sqrt(N - 1);
  R_ast = qr_R(x)[1:K, ] / sqrt(N - 1);
  R_ast_inverse = inverse(R_ast);
}
parameters {
  real alpha;           // intercept
  vector[K] theta;      // coefficients on Q_ast
  real<lower=0> sigma;  // error scale
}
model {
  y ~ student_t(nu, Q_ast * theta + alpha, sigma);  // likelihood
}
generated quantities {
  vector[K] beta;
  beta = R_ast_inverse * theta; // coefficients on x
}

```

```{r}

robust_noise_then = Sys.time()

robust_noise =
  sampling(
    robust_noise_model,
    data = robust_noise_data,
    iter = 1000,
    chains = 3,
    refresh = 50,
    warmup = 250
  )

robust_noise_time = difftime(Sys.time(), robust_noise_then)

robust_noise_time

robust_noise_out = rstan::extract(robust_noise)

robust_noise_avg = lapply(robust_noise_out, function(x) colMeans(as.matrix(x)))

robust_noise_ggdata =
  data.frame(
    beta1 = robust_noise_out$beta[,1],
    beta2 = robust_noise_out$beta[,2],
    alpha = robust_noise_out$alpha,
    sigma = robust_noise_out$sigma
  ) %>%
  pivot_longer(
    cols = everything(),
    names_to = "param",
    values_to = "value"
  )

robust_noise_act =
  data.frame(
    param = c("beta1", "beta2", "alpha", "sigma"),
    value = c(beta_1_4, alpha_1_4, sigma_1_4)
  )

ggplot() + 
  geom_boxplot(
    data = robust_noise_ggdata,
    aes(
      x = factor(param),
      y = value,
      color = param
    )
  ) + 
  geom_point(
    data = robust_noise_act,
    aes(
      x = factor(param),
      y = value
    )
  ) + 
  theme(
    legend.position = "none"
  ) + 
  labs(
    title = "1.4 Robust Noise Models",
    y = "Value",
    x = "Parameter"
  ) +
  facet_wrap(
    ~ param,
    scales = "free"
  )

```

## Logistic and Probit Regression

```{r}

u_1_5 = runif(n_samples)
x_1_5 = runif(n_samples)
alpha_1_5 = 2
beta_1_5 = 0.1
logit_inv_1_5 = 1/(1 + exp(-(alpha_1_5 + beta_1_5 * x_1_5)))
y_1_5 = u_1_5 < logit_inv_1_5

log_and_pro_data =
  list(
    N = n_samples,
    x = x_1_5, 
    y = y_1_5
  )

```

```{stan, output.var = "log_and_pro_model"}

data {
  int<lower=0> N;
  vector[N] x;
  int<lower=0,upper=1> y[N];
}
parameters {
  real alpha;
  real beta;
}
model {
  
  // Logistic
  y ~ bernoulli_logit(alpha + beta * x);
  
  // Probit 
  // y ~ bernoulli(Phi(alpha + beta * x));
  
}

```

```{r}

log_and_pro_then = Sys.time()

log_and_pro =
  sampling(
    log_and_pro_model,
    data = log_and_pro_data,
    iter = 1000,
    chains = 3,
    refresh = 50,
    warmup = 250
  )

log_and_pro_time = difftime(Sys.time(), log_and_pro_then)

log_and_pro_time

log_and_pro_out = rstan::extract(log_and_pro)

log_and_pro_avg = lapply(log_and_pro_out, function(x) colMeans(as.matrix(x)))

log_and_pro_ggdata =
  data.frame(
    alpha = log_and_pro_out$alpha,
    beta = log_and_pro_out$beta
  ) %>%
  pivot_longer(
    cols = everything(),
    names_to = "param",
    values_to = "value"
  )

log_and_pro_act =
  data.frame(
    param = c("alpha", "beta"),
    value = c(alpha_1_5, beta_1_5)
  )

ggplot() + 
  geom_boxplot(
    data = log_and_pro_ggdata,
    aes(
      x = factor(param),
      y = value,
      color = param
    )
  ) + 
  geom_point(
    data = log_and_pro_act,
    aes(
      x = factor(param),
      y = value
    )
  ) + 
  theme(
    legend.position = "none"
  ) + 
  labs(
    title = "1.5 Logistic and Probit Regression",
    y = "Value",
    x = "Parameter"
  ) +
  facet_wrap(
    ~ param,
    scales = "free"
  )

```

## Multi-Logit Regression

```{r}

k_1_6 = 3 # Possible output variables for y
d_1_6 = 2
x_1_6 = matrix(runif(n_samples * d_1_6), n_samples, d_1_6)
beta_1_6 = matrix(c(2, 1.5, 1.4, 2, 1.7, 1.8), d_1_6, k_1_6)
x_beta_1_6 = x_1_6 %*% beta_1_6

softmax =  function(u) exp(u) / sum(exp(u))

sm_1_6 = t(apply(x_beta_1_6, 1, softmax))

y_1_6 = apply(sm_1_6, 1, which.max)

multi_logit_data =
  list(
    N = n_samples,
    D = d_1_6,
    K = k_1_6,
    x = x_1_6, 
    y = y_1_6
  )

```

```{stan, output.var = "multi_logit_model"}

data {
  int K;
  int N;
  int D;
  int y[N];
  matrix[N, D] x;
}
parameters {
  matrix[D, K] beta;
}
model {
  matrix[N, K] x_beta = x * beta;

  to_vector(beta) ~ normal(1.5, 0.1);

  for (n in 1:N)
    y[n] ~ categorical_logit(x_beta[n]');
}

```

```{r}

multi_logit_then = Sys.time()

multi_logit =
  sampling(
    multi_logit_model,
    data = multi_logit_data,
    iter = 1000,
    chains = 3,
    refresh = 10,
    warmup = 250
  )

multi_logit_time = difftime(Sys.time(), multi_logit_then)

multi_logit_time

multi_logit_out = rstan::extract(multi_logit)

multi_logit_avg = apply(multi_logit_out$beta, c(2, 3), mean)

multi_logit_ggdata =
  data.frame(
    beta = multi_logit_out$beta
  ) %>%
  pivot_longer(
    cols = everything(),
    names_to = "param",
    values_to = "value"
  )

multi_logit_act =
  data.frame(
    param = paste0("beta.", rep(seq(d_1_6), k_1_6), ".", rep(seq(k_1_6), rep(d_1_6, k_1_6))),
    value = c(beta_1_6)
  )

ggplot() + 
  geom_boxplot(
    data = multi_logit_ggdata,
    aes(
      x = factor(param),
      y = value,
      color = param
    )
  ) + 
  geom_point(
    data = multi_logit_act,
    aes(
      x = factor(param),
      y = value
    )
  ) + 
  theme(
    legend.position = "none"
  ) + 
  labs(
    title = "1.6 Multi-Logit Regression",
    y = "Value",
    x = "Parameter"
  ) +
  facet_wrap(
    ~ param,
    scales = "free"
  )

```

## Parameterizing Centered Vectors

```{r}

k_1_7 = 3 # Possible output variables for y

stan_1_7_data =
  list(
    K = k_1_7
  )

```

```{stan, output.var = "stan_1_7"}

data{
  int K;
}

transformed data{
  matrix[K, K] A = diag_matrix(rep_vector(1,K));
  matrix[K, K-1] A_qr;
  for (i in 1:K-1) A[K,i] = -1;
  A[K,K] = 0;
  A_qr = qr_Q(A)[ , 1:(K-1)];
}
parameters {
  vector[K-1] beta_raw;
}
transformed parameters{
   vector[K] beta =  A_qr * beta_raw;
}
model {
  beta_raw ~ normal(0, inv(sqrt(1 - inv(K))));
}

```

```{r}

stan_1_7_then = Sys.time()

stan_1_7_model =
  sampling(
    stan_1_7,
    data = stan_1_7_data,
    iter = 1000,
    chains = 3,
    refresh = 10,
    warmup = 250
  )

stan_1_7_time = difftime(Sys.time(), stan_1_7_then)

stan_1_7_time

stan_1_7_out = rstan::extract(stan_1_7_model)

```

## Ordered Logistic Regression

```{r}

k_1_8 = 3 # Possible output variables for y
d_1_8 = 2
n_1_8 = 1000
x_1_8 = matrix(runif(d_1_8 * n_1_8), d_1_8, n_1_8) 
beta_1_8 = c(1, 2) # Length D
x_beta_1_8 = x_1_8 %*% beta_1_8
c_1_8 = c(1.5) # Length K - 1

y_1_8 = case_when(x_beta_1_8 < c_1_8 ~ 1L,
                  TRUE ~ 2L) # 1 <= y <= K

stan_1_8_data =
  list(
    K = k_1_8,
    N = n_1_8,
    D = d_1_8,
    y = y_1_8,
    x = x_1_8
  )

```

```{stan, output.var = "stan_1_8"}

data {
  int<lower=2> K;
  int<lower=0> N;
  int<lower=1> D;
  int<lower=1, upper=K> y[N];
  row_vector[D] x[N];
}
parameters {
  vector[D] beta;
  ordered[K-1] c;
}
model {
  for (n in 1:N)
    y[n] ~ ordered_logistic(x[n] * beta, c);
}

```

```{r}

stan_1_8_then = Sys.time()

stan_1_8_model =
  sampling(
    stan_1_8,
    data = stan_1_8_data,
    iter = 1000,
    chains = 3,
    refresh = 10,
    warmup = 250
  )

stan_1_8_time = difftime(Sys.time(), stan_1_8_then)

stan_1_8_time

stan_1_8_out = rstan::extract(stan_1_8_model)

```
